{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4c22ba2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Visualization with HoloViz.'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"Visualization with HoloViz.\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fb7e9bd",
   "metadata": {},
   "source": [
    "# Визуализация с HoloViz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bee1760c",
   "metadata": {},
   "source": [
    "Если вы пытались визуализировать pandas.DataFrame раньше, то вы, вероятно, сталкивались с Pandas .plot() API. Эти команды используют Matplotlib для рендеринга статических PNG или SVG в Jupyter блокнотах с использованием встроенного бэкэнда или интерактивных графиков через %matplotlib widget.\n",
    "\n",
    "API-интерфейс Pandas .plot() стал де-факто стандартом для высокоуровневого построения графиков в Python и теперь поддерживается множеством различных библиотек, которые используют набор базовых механизмов построения графиков для обеспечения дополнительных возможностей. Библиотеки, которые в настоящее время поддерживают этот API, включают:\n",
    "\n",
    "- [Pandas](https://pandas.pydata.org/pandas-docs/stable/user_guide/visualization.html) - API на основе Matplotlib, включенный в Pandas (статический или интерактивный вывод в Jupyter блокнотах).\n",
    "- [xarray](https://xarray.pydata.org/en/stable/plotting.html) - API на основе Matplotlib, включенный в xarray, на основе pandas .plot API (статический или интерактивный вывод в Jupyter блокнотах).\n",
    "- [hvPlot](https://hvplot.pyviz.org/) - интерактивные графики на основе HoloViews и Bokeh для данных Pandas, GeoPandas, xarray, Dask, Intake и Streamz.\n",
    "- [Pandas Bokeh](https://github.com/PatrikHlobil/Pandas-Bokeh) - интерактивные графики на основе Bokeh для данных Pandas, GeoPandas и PySpark.\n",
    "- [Cufflinks](https://github.com/santosjorge/cufflinks) - графические интерактивные графики для данных Pandas.\n",
    "- [Plotly Express](https://plotly.com/python/pandas-backend) - интерактивные графики на основе Plotly-Express для данных Pandas; только частичная поддержка ключевых аргументов API .plot.\n",
    "- [PdVega](https://altair-viz.github.io/pdvega) - интерактивные графики на основе Vega-lite в JSON-формате для данных Pandas.\n",
    "\n",
    "В этом блокноте мы исследуем возможности стандартного API `.plot` и продемонстрируем дополнительные возможности, предоставляемые `.hvplot`, которые включают бесшовную интерактивность в развернутых информационных панелях и рендеринг на стороне сервера больших наборов данных.\n",
    "\n",
    "Чтобы показать эти особенности, мы будем использовать набор данных в виде таблиц о землетрясениях и других запрошенных сейсмологических событиях из [Каталога землетрясений USGS](https://earthquake.usgs.gov/earthquakes/search), используя его [API](https://github.com/pyviz/holoviz/wiki/Creating-the-USGS-Earthquake-dataset). Конечно, этот набор данных является всего лишь примером; тот же подход можно использовать практически с любым табличным набором данных, и аналогичные подходы можно использовать с [наборами данных с координатной привязкой (многомерный массив)](https://hvplot.holoviz.org/user_guide/Gridded_Data.html).\n",
    "\n",
    "Для работы с пакетом [hvplot](https://hvplot.holoviz.org/user_guide/Gridded_Data.html) понадобится настроить программное окружение (установить множество модулей).\n",
    "\n",
    "Я предпочитаю работать с [miniconda](https://docs.conda.io/projects/conda/en/latest/user-guide/install/download.html) и раздельными виртуальными средами.\n",
    "\n",
    "Далее в командной строке для настройки среды окружения необходимо выполнить:\n",
    "\n",
    "```shell\n",
    "    conda create --name holoviz\n",
    "    conda activate holoviz\n",
    "    conda install anaconda-project\n",
    "    anaconda-project download pyviz/holoviz_tutorial\n",
    "    cd holoviz_tutorial\n",
    "    anaconda-project run jupyter lab\n",
    "```\n",
    "\n",
    "После процесса установки всех необходимых модулей и запуска Jupyter Lab можно открыть оригинал данного блокнота: tutorial/02_Plotting.ipynb.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04e7558c",
   "metadata": {},
   "source": [
    "# Чтение данных"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77893338",
   "metadata": {},
   "source": [
    "Здесь мы сосредоточимся на Pandas, но аналогичный подход будет работать для любого поддерживаемого типа DataFrame, включая Dask для распределенных вычислений или RAPIDS cuDF для вычислений на GPU. Этот набор данных относительно велик (2,1 млн строк), но он все равно должен уместиться в памяти на любой современной машине и, следовательно, не потребует специальных внепроцессорных или распределенных подходов, таких как Dask."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "27c879fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script type=\"esms-options\">{\"shimMode\": true}</script><style>*[data-root-id],\n",
       "*[data-root-id] > * {\n",
       "  box-sizing: border-box;\n",
       "  font-family: var(--jp-ui-font-family);\n",
       "  font-size: var(--jp-ui-font-size1);\n",
       "  color: var(--vscode-editor-foreground, var(--jp-ui-font-color1));\n",
       "}\n",
       "\n",
       "/* Override VSCode background color */\n",
       ".cell-output-ipywidget-background:has(\n",
       "  > .cell-output-ipywidget-background > .lm-Widget > *[data-root-id]\n",
       "),\n",
       ".cell-output-ipywidget-background:has(> .lm-Widget > *[data-root-id]) {\n",
       "  background-color: transparent !important;\n",
       "}\n",
       "</style>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": "(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  const force = true;\n  const py_version = '3.8.1'.replace('rc', '-rc.').replace('.dev', '-dev.');\n  const reloading = false;\n  const Bokeh = root.Bokeh;\n\n  // Set a timeout for this load but only if we are not already initializing\n  if (typeof (root._bokeh_timeout) === \"undefined\" || (force || !root._bokeh_is_initializing)) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) {\n        if (callback != null)\n          callback();\n      });\n    } finally {\n      delete root._bokeh_onload_callbacks;\n    }\n    console.debug(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(css_urls, js_urls, js_modules, js_exports, callback) {\n    if (css_urls == null) css_urls = [];\n    if (js_urls == null) js_urls = [];\n    if (js_modules == null) js_modules = [];\n    if (js_exports == null) js_exports = {};\n\n    root._bokeh_onload_callbacks.push(callback);\n\n    if (root._bokeh_is_loading > 0) {\n      // Don't load bokeh if it is still initializing\n      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    } else if (js_urls.length === 0 && js_modules.length === 0 && Object.keys(js_exports).length === 0) {\n      // There is nothing to load\n      run_callbacks();\n      return null;\n    }\n\n    function on_load() {\n      root._bokeh_is_loading--;\n      if (root._bokeh_is_loading === 0) {\n        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n        run_callbacks()\n      }\n    }\n    window._bokeh_on_load = on_load\n\n    function on_error(e) {\n      const src_el = e.srcElement\n      console.error(\"failed to load \" + (src_el.href || src_el.src));\n    }\n\n    const skip = [];\n    if (window.requirejs) {\n      window.requirejs.config({'packages': {}, 'paths': {}, 'shim': {}});\n      root._bokeh_is_loading = css_urls.length + 0;\n    } else {\n      root._bokeh_is_loading = css_urls.length + js_urls.length + js_modules.length + Object.keys(js_exports).length;\n    }\n\n    const existing_stylesheets = []\n    const links = document.getElementsByTagName('link')\n    for (let i = 0; i < links.length; i++) {\n      const link = links[i]\n      if (link.href != null) {\n        existing_stylesheets.push(link.href)\n      }\n    }\n    for (let i = 0; i < css_urls.length; i++) {\n      const url = css_urls[i];\n      const escaped = encodeURI(url)\n      if (existing_stylesheets.indexOf(escaped) !== -1) {\n        on_load()\n        continue;\n      }\n      const element = document.createElement(\"link\");\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.rel = \"stylesheet\";\n      element.type = \"text/css\";\n      element.href = url;\n      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n      document.body.appendChild(element);\n    }    var existing_scripts = []\n    const scripts = document.getElementsByTagName('script')\n    for (let i = 0; i < scripts.length; i++) {\n      var script = scripts[i]\n      if (script.src != null) {\n        existing_scripts.push(script.src)\n      }\n    }\n    for (let i = 0; i < js_urls.length; i++) {\n      const url = js_urls[i];\n      const escaped = encodeURI(url)\n      if (skip.indexOf(escaped) !== -1 || existing_scripts.indexOf(escaped) !== -1) {\n        if (!window.requirejs) {\n          on_load();\n        }\n        continue;\n      }\n      const element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.async = false;\n      element.src = url;\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n    for (let i = 0; i < js_modules.length; i++) {\n      const url = js_modules[i];\n      const escaped = encodeURI(url)\n      if (skip.indexOf(escaped) !== -1 || existing_scripts.indexOf(escaped) !== -1) {\n        if (!window.requirejs) {\n          on_load();\n        }\n        continue;\n      }\n      var element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.async = false;\n      element.src = url;\n      element.type = \"module\";\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n    for (const name in js_exports) {\n      const url = js_exports[name];\n      const escaped = encodeURI(url)\n      if (skip.indexOf(escaped) >= 0 || root[name] != null) {\n        if (!window.requirejs) {\n          on_load();\n        }\n        continue;\n      }\n      var element = document.createElement('script');\n      element.onerror = on_error;\n      element.async = false;\n      element.type = \"module\";\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      element.textContent = `\n      import ${name} from \"${url}\"\n      window.${name} = ${name}\n      window._bokeh_on_load()\n      `\n      document.head.appendChild(element);\n    }\n    if (!js_urls.length && !js_modules.length) {\n      on_load()\n    }\n  };\n\n  function inject_raw_css(css) {\n    const element = document.createElement(\"style\");\n    element.appendChild(document.createTextNode(css));\n    document.body.appendChild(element);\n  }\n\n  const js_urls = [\"https://cdn.holoviz.org/panel/1.8.3/dist/bundled/reactiveesm/es-module-shims@^1.10.0/dist/es-module-shims.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-3.8.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-3.8.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-3.8.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-3.8.1.min.js\", \"https://cdn.holoviz.org/panel/1.8.3/dist/panel.min.js\"];\n  const js_modules = [];\n  const js_exports = {};\n  const css_urls = [];\n  const inline_js = [    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\nfunction(Bokeh) {} // ensure no trailing comma for IE\n  ];\n\n  function run_inline_js() {\n    if ((root.Bokeh !== undefined) || (force === true)) {\n      for (let i = 0; i < inline_js.length; i++) {\n        try {\n          inline_js[i].call(root, root.Bokeh);\n        } catch(e) {\n          if (!reloading) {\n            throw e;\n          }\n        }\n      }\n      // Cache old bokeh versions\n      if (Bokeh != undefined && !reloading) {\n        var NewBokeh = root.Bokeh;\n        if (Bokeh.versions === undefined) {\n          Bokeh.versions = new Map();\n        }\n        if (NewBokeh.version !== Bokeh.version) {\n          Bokeh.versions.set(NewBokeh.version, NewBokeh)\n        }\n        root.Bokeh = Bokeh;\n      }\n    } else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    }\n    root._bokeh_is_initializing = false\n  }\n\n  function load_or_wait() {\n    // Implement a backoff loop that tries to ensure we do not load multiple\n    // versions of Bokeh and its dependencies at the same time.\n    // In recent versions we use the root._bokeh_is_initializing flag\n    // to determine whether there is an ongoing attempt to initialize\n    // bokeh, however for backward compatibility we also try to ensure\n    // that we do not start loading a newer (Panel>=1.0 and Bokeh>3) version\n    // before older versions are fully initialized.\n    if (root._bokeh_is_initializing && Date.now() > root._bokeh_timeout) {\n      // If the timeout and bokeh was not successfully loaded we reset\n      // everything and try loading again\n      root._bokeh_timeout = Date.now() + 5000;\n      root._bokeh_is_initializing = false;\n      root._bokeh_onload_callbacks = undefined;\n      root._bokeh_is_loading = 0\n      console.log(\"Bokeh: BokehJS was loaded multiple times but one version failed to initialize.\");\n      load_or_wait();\n    } else if (root._bokeh_is_initializing || (typeof root._bokeh_is_initializing === \"undefined\" && root._bokeh_onload_callbacks !== undefined)) {\n      setTimeout(load_or_wait, 100);\n    } else {\n      root._bokeh_is_initializing = true\n      root._bokeh_onload_callbacks = []\n      const bokeh_loaded = root.Bokeh != null && (root.Bokeh.version === py_version || (root.Bokeh.versions !== undefined && root.Bokeh.versions.has(py_version)));\n      if (!reloading && !bokeh_loaded) {\n        if (root.Bokeh) {\n          root.Bokeh = undefined;\n        }\n        console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n      }\n      load_libs(css_urls, js_urls, js_modules, js_exports, function() {\n        console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n        run_inline_js();\n      });\n    }\n  }\n  // Give older versions of the autoload script a head-start to ensure\n  // they initialize before we start loading newer version.\n  setTimeout(load_or_wait, 100)\n}(window));",
      "application/vnd.holoviews_load.v0+json": ""
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": "\nif ((window.PyViz === undefined) || (window.PyViz instanceof HTMLElement)) {\n  window.PyViz = {comms: {}, comm_status:{}, kernels:{}, receivers: {}, plot_index: []}\n}\n\n\n    function JupyterCommManager() {\n    }\n\n    JupyterCommManager.prototype.register_target = function(plot_id, comm_id, msg_handler) {\n      if (window.comm_manager || ((window.Jupyter !== undefined) && (Jupyter.notebook.kernel != null))) {\n        var comm_manager = window.comm_manager || Jupyter.notebook.kernel.comm_manager;\n        comm_manager.register_target(comm_id, function(comm) {\n          comm.on_msg(msg_handler);\n        });\n      } else if ((plot_id in window.PyViz.kernels) && (window.PyViz.kernels[plot_id])) {\n        window.PyViz.kernels[plot_id].registerCommTarget(comm_id, function(comm) {\n          comm.onMsg = msg_handler;\n        });\n      } else if (typeof google != 'undefined' && google.colab.kernel != null) {\n        google.colab.kernel.comms.registerTarget(comm_id, (comm) => {\n          var messages = comm.messages[Symbol.asyncIterator]();\n          function processIteratorResult(result) {\n            var message = result.value;\n            var content = {data: message.data, comm_id};\n            var buffers = []\n            for (var buffer of message.buffers || []) {\n              buffers.push(new DataView(buffer))\n            }\n            var metadata = message.metadata || {};\n            var msg = {content, buffers, metadata}\n            msg_handler(msg);\n            return messages.next().then(processIteratorResult);\n          }\n          return messages.next().then(processIteratorResult);\n        })\n      }\n    }\n\n    JupyterCommManager.prototype.get_client_comm = function(plot_id, comm_id, msg_handler) {\n      if (comm_id in window.PyViz.comms) {\n        return window.PyViz.comms[comm_id];\n      } else if (window.comm_manager || ((window.Jupyter !== undefined) && (Jupyter.notebook.kernel != null))) {\n        var comm_manager = window.comm_manager || Jupyter.notebook.kernel.comm_manager;\n        var comm = comm_manager.new_comm(comm_id, {}, {}, {}, comm_id);\n        if (msg_handler) {\n          comm.on_msg(msg_handler);\n        }\n      } else if ((plot_id in window.PyViz.kernels) && (window.PyViz.kernels[plot_id])) {\n        var comm = window.PyViz.kernels[plot_id].connectToComm(comm_id);\n        let retries = 0;\n        const open = () => {\n          if (comm.active) {\n            comm.open();\n          } else if (retries > 3) {\n            console.warn('Comm target never activated')\n          } else {\n            retries += 1\n            setTimeout(open, 500)\n          }\n        }\n        if (comm.active) {\n          comm.open();\n        } else {\n          setTimeout(open, 500)\n        }\n        if (msg_handler) {\n          comm.onMsg = msg_handler;\n        }\n      } else if (typeof google != 'undefined' && google.colab.kernel != null) {\n        var comm_promise = google.colab.kernel.comms.open(comm_id)\n        comm_promise.then((comm) => {\n          window.PyViz.comms[comm_id] = comm;\n          if (msg_handler) {\n            var messages = comm.messages[Symbol.asyncIterator]();\n            function processIteratorResult(result) {\n              var message = result.value;\n              var content = {data: message.data};\n              var metadata = message.metadata || {comm_id};\n              var msg = {content, metadata}\n              msg_handler(msg);\n              return messages.next().then(processIteratorResult);\n            }\n            return messages.next().then(processIteratorResult);\n          }\n        })\n        var sendClosure = (data, metadata, buffers, disposeOnDone) => {\n          return comm_promise.then((comm) => {\n            comm.send(data, metadata, buffers, disposeOnDone);\n          });\n        };\n        var comm = {\n          send: sendClosure\n        };\n      }\n      window.PyViz.comms[comm_id] = comm;\n      return comm;\n    }\n    window.PyViz.comm_manager = new JupyterCommManager();\n    \n\n\nvar JS_MIME_TYPE = 'application/javascript';\nvar HTML_MIME_TYPE = 'text/html';\nvar EXEC_MIME_TYPE = 'application/vnd.holoviews_exec.v0+json';\nvar CLASS_NAME = 'output';\n\n/**\n * Render data to the DOM node\n */\nfunction render(props, node) {\n  var div = document.createElement(\"div\");\n  var script = document.createElement(\"script\");\n  node.appendChild(div);\n  node.appendChild(script);\n}\n\n/**\n * Handle when a new output is added\n */\nfunction handle_add_output(event, handle) {\n  var output_area = handle.output_area;\n  var output = handle.output;\n  if ((output.data == undefined) || (!output.data.hasOwnProperty(EXEC_MIME_TYPE))) {\n    return\n  }\n  var id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n  var toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n  if (id !== undefined) {\n    var nchildren = toinsert.length;\n    var html_node = toinsert[nchildren-1].children[0];\n    html_node.innerHTML = output.data[HTML_MIME_TYPE];\n    var scripts = [];\n    var nodelist = html_node.querySelectorAll(\"script\");\n    for (var i in nodelist) {\n      if (nodelist.hasOwnProperty(i)) {\n        scripts.push(nodelist[i])\n      }\n    }\n\n    scripts.forEach( function (oldScript) {\n      var newScript = document.createElement(\"script\");\n      var attrs = [];\n      var nodemap = oldScript.attributes;\n      for (var j in nodemap) {\n        if (nodemap.hasOwnProperty(j)) {\n          attrs.push(nodemap[j])\n        }\n      }\n      attrs.forEach(function(attr) { newScript.setAttribute(attr.name, attr.value) });\n      newScript.appendChild(document.createTextNode(oldScript.innerHTML));\n      oldScript.parentNode.replaceChild(newScript, oldScript);\n    });\n    if (JS_MIME_TYPE in output.data) {\n      toinsert[nchildren-1].children[1].textContent = output.data[JS_MIME_TYPE];\n    }\n    output_area._hv_plot_id = id;\n    if ((window.Bokeh !== undefined) && (id in Bokeh.index)) {\n      window.PyViz.plot_index[id] = Bokeh.index[id];\n    } else {\n      window.PyViz.plot_index[id] = null;\n    }\n  } else if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n    var bk_div = document.createElement(\"div\");\n    bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n    var script_attrs = bk_div.children[0].attributes;\n    for (var i = 0; i < script_attrs.length; i++) {\n      toinsert[toinsert.length - 1].childNodes[1].setAttribute(script_attrs[i].name, script_attrs[i].value);\n    }\n    // store reference to server id on output_area\n    output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n  }\n}\n\n/**\n * Handle when an output is cleared or removed\n */\nfunction handle_clear_output(event, handle) {\n  var id = handle.cell.output_area._hv_plot_id;\n  var server_id = handle.cell.output_area._bokeh_server_id;\n  if (((id === undefined) || !(id in PyViz.plot_index)) && (server_id !== undefined)) { return; }\n  var comm = window.PyViz.comm_manager.get_client_comm(\"hv-extension-comm\", \"hv-extension-comm\", function () {});\n  if (server_id !== null) {\n    comm.send({event_type: 'server_delete', 'id': server_id});\n    return;\n  } else if (comm !== null) {\n    comm.send({event_type: 'delete', 'id': id});\n  }\n  delete PyViz.plot_index[id];\n  if ((window.Bokeh !== undefined) & (id in window.Bokeh.index)) {\n    var doc = window.Bokeh.index[id].model.document\n    doc.clear();\n    const i = window.Bokeh.documents.indexOf(doc);\n    if (i > -1) {\n      window.Bokeh.documents.splice(i, 1);\n    }\n  }\n}\n\n/**\n * Handle kernel restart event\n */\nfunction handle_kernel_cleanup(event, handle) {\n  delete PyViz.comms[\"hv-extension-comm\"];\n  window.PyViz.plot_index = {}\n}\n\n/**\n * Handle update_display_data messages\n */\nfunction handle_update_output(event, handle) {\n  handle_clear_output(event, {cell: {output_area: handle.output_area}})\n  handle_add_output(event, handle)\n}\n\nfunction register_renderer(events, OutputArea) {\n  function append_mime(data, metadata, element) {\n    // create a DOM node to render to\n    var toinsert = this.create_output_subarea(\n    metadata,\n    CLASS_NAME,\n    EXEC_MIME_TYPE\n    );\n    this.keyboard_manager.register_events(toinsert);\n    // Render to node\n    var props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n    render(props, toinsert[0]);\n    element.append(toinsert);\n    return toinsert\n  }\n\n  events.on('output_added.OutputArea', handle_add_output);\n  events.on('output_updated.OutputArea', handle_update_output);\n  events.on('clear_output.CodeCell', handle_clear_output);\n  events.on('delete.Cell', handle_clear_output);\n  events.on('kernel_ready.Kernel', handle_kernel_cleanup);\n\n  OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n    safe: true,\n    index: 0\n  });\n}\n\nif (window.Jupyter !== undefined) {\n  try {\n    var events = require('base/js/events');\n    var OutputArea = require('notebook/js/outputarea').OutputArea;\n    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n      register_renderer(events, OutputArea);\n    }\n  } catch(err) {\n  }\n}\n",
      "application/vnd.holoviews_load.v0+json": ""
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.holoviews_exec.v0+json": "",
      "text/html": [
       "<div id='0ae180c1-54f2-4be7-9b45-dddcb4fd4b21'>\n",
       "  <div id=\"c3d804d3-10ee-41be-ac08-322f453d5e99\" data-root-id=\"0ae180c1-54f2-4be7-9b45-dddcb4fd4b21\" style=\"display: contents;\"></div>\n",
       "</div>\n",
       "<script type=\"application/javascript\">(function(root) {\n",
       "  var docs_json = {\"5c212164-bd25-4479-853c-fd4388de1281\":{\"version\":\"3.8.1\",\"title\":\"Bokeh Application\",\"config\":{\"type\":\"object\",\"name\":\"DocumentConfig\",\"id\":\"b8b97429-0a38-47c2-a885-16a5750d08b4\",\"attributes\":{\"notifications\":{\"type\":\"object\",\"name\":\"Notifications\",\"id\":\"4ce47135-7f80-46bf-bc8c-b613f56c01c9\"}}},\"roots\":[{\"type\":\"object\",\"name\":\"panel.models.browser.BrowserInfo\",\"id\":\"0ae180c1-54f2-4be7-9b45-dddcb4fd4b21\"},{\"type\":\"object\",\"name\":\"panel.models.comm_manager.CommManager\",\"id\":\"67e43076-01a9-4f5c-8491-af2e9848b5a9\",\"attributes\":{\"plot_id\":\"0ae180c1-54f2-4be7-9b45-dddcb4fd4b21\",\"comm_id\":\"a2c1659b751d4309932e126b5b4f62f1\",\"client_comm_id\":\"76606baeff3b4582848f22e7128ff63c\"}}],\"defs\":[{\"type\":\"model\",\"name\":\"ReactiveHTML1\"},{\"type\":\"model\",\"name\":\"FlexBox1\",\"properties\":[{\"name\":\"align_content\",\"kind\":\"Any\",\"default\":\"flex-start\"},{\"name\":\"align_items\",\"kind\":\"Any\",\"default\":\"flex-start\"},{\"name\":\"flex_direction\",\"kind\":\"Any\",\"default\":\"row\"},{\"name\":\"flex_wrap\",\"kind\":\"Any\",\"default\":\"wrap\"},{\"name\":\"gap\",\"kind\":\"Any\",\"default\":\"\"},{\"name\":\"justify_content\",\"kind\":\"Any\",\"default\":\"flex-start\"}]},{\"type\":\"model\",\"name\":\"FloatPanel1\",\"properties\":[{\"name\":\"config\",\"kind\":\"Any\",\"default\":{\"type\":\"map\"}},{\"name\":\"contained\",\"kind\":\"Any\",\"default\":true},{\"name\":\"position\",\"kind\":\"Any\",\"default\":\"right-top\"},{\"name\":\"offsetx\",\"kind\":\"Any\",\"default\":null},{\"name\":\"offsety\",\"kind\":\"Any\",\"default\":null},{\"name\":\"theme\",\"kind\":\"Any\",\"default\":\"primary\"},{\"name\":\"status\",\"kind\":\"Any\",\"default\":\"normalized\"}]},{\"type\":\"model\",\"name\":\"GridStack1\",\"properties\":[{\"name\":\"ncols\",\"kind\":\"Any\",\"default\":null},{\"name\":\"nrows\",\"kind\":\"Any\",\"default\":null},{\"name\":\"allow_resize\",\"kind\":\"Any\",\"default\":true},{\"name\":\"allow_drag\",\"kind\":\"Any\",\"default\":true},{\"name\":\"state\",\"kind\":\"Any\",\"default\":[]}]},{\"type\":\"model\",\"name\":\"drag1\",\"properties\":[{\"name\":\"slider_width\",\"kind\":\"Any\",\"default\":5},{\"name\":\"slider_color\",\"kind\":\"Any\",\"default\":\"black\"},{\"name\":\"start\",\"kind\":\"Any\",\"default\":0},{\"name\":\"end\",\"kind\":\"Any\",\"default\":100},{\"name\":\"value\",\"kind\":\"Any\",\"default\":50}]},{\"type\":\"model\",\"name\":\"click1\",\"properties\":[{\"name\":\"terminal_output\",\"kind\":\"Any\",\"default\":\"\"},{\"name\":\"debug_name\",\"kind\":\"Any\",\"default\":\"\"},{\"name\":\"clears\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"ReactiveESM1\",\"properties\":[{\"name\":\"esm_constants\",\"kind\":\"Any\",\"default\":{\"type\":\"map\"}}]},{\"type\":\"model\",\"name\":\"JSComponent1\",\"properties\":[{\"name\":\"esm_constants\",\"kind\":\"Any\",\"default\":{\"type\":\"map\"}}]},{\"type\":\"model\",\"name\":\"ReactComponent1\",\"properties\":[{\"name\":\"use_shadow_dom\",\"kind\":\"Any\",\"default\":true},{\"name\":\"esm_constants\",\"kind\":\"Any\",\"default\":{\"type\":\"map\"}}]},{\"type\":\"model\",\"name\":\"AnyWidgetComponent1\",\"properties\":[{\"name\":\"use_shadow_dom\",\"kind\":\"Any\",\"default\":true},{\"name\":\"esm_constants\",\"kind\":\"Any\",\"default\":{\"type\":\"map\"}}]},{\"type\":\"model\",\"name\":\"FastWrapper1\",\"properties\":[{\"name\":\"object\",\"kind\":\"Any\",\"default\":null},{\"name\":\"style\",\"kind\":\"Any\",\"default\":null}]},{\"type\":\"model\",\"name\":\"NotificationArea1\",\"properties\":[{\"name\":\"js_events\",\"kind\":\"Any\",\"default\":{\"type\":\"map\"}},{\"name\":\"max_notifications\",\"kind\":\"Any\",\"default\":5},{\"name\":\"notifications\",\"kind\":\"Any\",\"default\":[]},{\"name\":\"position\",\"kind\":\"Any\",\"default\":\"bottom-right\"},{\"name\":\"_clear\",\"kind\":\"Any\",\"default\":0},{\"name\":\"types\",\"kind\":\"Any\",\"default\":[{\"type\":\"map\",\"entries\":[[\"type\",\"warning\"],[\"background\",\"#ffc107\"],[\"icon\",{\"type\":\"map\",\"entries\":[[\"className\",\"fas fa-exclamation-triangle\"],[\"tagName\",\"i\"],[\"color\",\"white\"]]}]]},{\"type\":\"map\",\"entries\":[[\"type\",\"info\"],[\"background\",\"#007bff\"],[\"icon\",{\"type\":\"map\",\"entries\":[[\"className\",\"fas fa-info-circle\"],[\"tagName\",\"i\"],[\"color\",\"white\"]]}]]}]}]},{\"type\":\"model\",\"name\":\"Notification\",\"properties\":[{\"name\":\"background\",\"kind\":\"Any\",\"default\":null},{\"name\":\"duration\",\"kind\":\"Any\",\"default\":3000},{\"name\":\"icon\",\"kind\":\"Any\",\"default\":null},{\"name\":\"message\",\"kind\":\"Any\",\"default\":\"\"},{\"name\":\"notification_type\",\"kind\":\"Any\",\"default\":null},{\"name\":\"_rendered\",\"kind\":\"Any\",\"default\":false},{\"name\":\"_destroyed\",\"kind\":\"Any\",\"default\":false}]},{\"type\":\"model\",\"name\":\"TemplateActions1\",\"properties\":[{\"name\":\"open_modal\",\"kind\":\"Any\",\"default\":0},{\"name\":\"close_modal\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"BootstrapTemplateActions1\",\"properties\":[{\"name\":\"open_modal\",\"kind\":\"Any\",\"default\":0},{\"name\":\"close_modal\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"TemplateEditor1\",\"properties\":[{\"name\":\"layout\",\"kind\":\"Any\",\"default\":[]}]},{\"type\":\"model\",\"name\":\"MaterialTemplateActions1\",\"properties\":[{\"name\":\"open_modal\",\"kind\":\"Any\",\"default\":0},{\"name\":\"close_modal\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"request_value1\",\"properties\":[{\"name\":\"fill\",\"kind\":\"Any\",\"default\":\"none\"},{\"name\":\"_synced\",\"kind\":\"Any\",\"default\":null},{\"name\":\"_request_sync\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"holoviews.plotting.bokeh.raster.HoverModel\",\"properties\":[{\"name\":\"xy\",\"kind\":\"Any\",\"default\":null},{\"name\":\"data\",\"kind\":\"Any\",\"default\":null}]}]}};\n",
       "  var render_items = [{\"docid\":\"5c212164-bd25-4479-853c-fd4388de1281\",\"roots\":{\"0ae180c1-54f2-4be7-9b45-dddcb4fd4b21\":\"c3d804d3-10ee-41be-ac08-322f453d5e99\"},\"root_ids\":[\"0ae180c1-54f2-4be7-9b45-dddcb4fd4b21\"]}];\n",
       "  var docs = Object.values(docs_json)\n",
       "  if (!docs) {\n",
       "    return\n",
       "  }\n",
       "  const py_version = docs[0].version.replace('rc', '-rc.').replace('.dev', '-dev.')\n",
       "  async function embed_document(root) {\n",
       "    var Bokeh = get_bokeh(root)\n",
       "    await Bokeh.embed.embed_items_notebook(docs_json, render_items);\n",
       "    for (const render_item of render_items) {\n",
       "      for (const root_id of render_item.root_ids) {\n",
       "\tconst id_el = document.getElementById(root_id)\n",
       "\tif (id_el.children.length && id_el.children[0].hasAttribute('data-root-id')) {\n",
       "\t  const root_el = id_el.children[0]\n",
       "\t  root_el.id = root_el.id + '-rendered'\n",
       "\t  for (const child of root_el.children) {\n",
       "            // Ensure JupyterLab does not capture keyboard shortcuts\n",
       "            // see: https://jupyterlab.readthedocs.io/en/4.1.x/extension/notebook.html#keyboard-interaction-model\n",
       "\t    child.setAttribute('data-lm-suppress-shortcuts', 'true')\n",
       "\t  }\n",
       "\t}\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "  function get_bokeh(root) {\n",
       "    if (root.Bokeh === undefined) {\n",
       "      return null\n",
       "    } else if (root.Bokeh.version !== py_version) {\n",
       "      if (root.Bokeh.versions === undefined || !root.Bokeh.versions.has(py_version)) {\n",
       "\treturn null\n",
       "      }\n",
       "      return root.Bokeh.versions.get(py_version);\n",
       "    } else if (root.Bokeh.version === py_version) {\n",
       "      return root.Bokeh\n",
       "    }\n",
       "    return null\n",
       "  }\n",
       "  function is_loaded(root) {\n",
       "    var Bokeh = get_bokeh(root)\n",
       "    return (Bokeh != null && Bokeh.Panel !== undefined)\n",
       "  }\n",
       "  if (is_loaded(root)) {\n",
       "    embed_document(root);\n",
       "  } else {\n",
       "    var attempts = 0;\n",
       "    var timer = setInterval(function(root) {\n",
       "      if (is_loaded(root)) {\n",
       "        clearInterval(timer);\n",
       "        embed_document(root);\n",
       "      } else if (document.readyState == \"complete\") {\n",
       "        attempts++;\n",
       "        if (attempts > 200) {\n",
       "          clearInterval(timer);\n",
       "\t  var Bokeh = get_bokeh(root)\n",
       "\t  if (Bokeh == null || Bokeh.Panel == null) {\n",
       "            console.warn(\"Panel: ERROR: Unable to run Panel code because Bokeh or Panel library is missing\");\n",
       "\t  } else {\n",
       "\t    console.warn(\"Panel: WARNING: Attempting to render but not all required libraries could be resolved.\")\n",
       "\t    embed_document(root)\n",
       "\t  }\n",
       "        }\n",
       "      }\n",
       "    }, 25, root)\n",
       "  }\n",
       "})(window);</script>"
      ]
     },
     "metadata": {
      "application/vnd.holoviews_exec.v0+json": {
       "id": "0ae180c1-54f2-4be7-9b45-dddcb4fd4b21"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import hvplot.pandas  # noqa: adds hvplot method to pandas objects\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cb9cfc9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "100   134  100   134    0     0    312      0 --:--:-- --:--:-- --:--:--   316\n",
      "\n",
      "100    17  100    17    0     0     19      0 --:--:-- --:--:-- --:--:--    19\n",
      "\n",
      "100   491    0   491    0     0    318      0 --:--:--  0:00:01 --:--:--   318\n",
      "100   491    0   491    0     0    318      0 --:--:--  0:00:01 --:--:--     0\n",
      "\n",
      "  1  116M    1 1440k    0     0   602k      0  0:03:18  0:00:02  0:03:16  602k\n",
      "  8  116M    8 9984k    0     0  2942k      0  0:00:40  0:00:03  0:00:37 8535k\n",
      " 16  116M   16 19.6M    0     0  4590k      0  0:00:25  0:00:04  0:00:21 9360k\n",
      " 24  116M   24 28.1M    0     0  5306k      0  0:00:22  0:00:05  0:00:17 9004k\n",
      " 29  116M   29 34.3M    0     0  5504k      0  0:00:21  0:00:06  0:00:15 8436k\n",
      " 32  116M   32 37.9M    0     0  5257k      0  0:00:22  0:00:07  0:00:15 7483k\n",
      " 35  116M   35 41.7M    0     0  5087k      0  0:00:23  0:00:08  0:00:15 6544k\n",
      " 38  116M   38 44.3M    0     0  4830k      0  0:00:24  0:00:09  0:00:15 5042k\n",
      " 40  116M   40 46.8M    0     0  4612k      0  0:00:25  0:00:10  0:00:15 3851k\n",
      " 42  116M   42 49.5M    0     0  4449k      0  0:00:26  0:00:11  0:00:15 3100k\n",
      " 46  116M   46 54.0M    0     0  4465k      0  0:00:26  0:00:12  0:00:14 3296k\n",
      " 53  116M   53 61.8M    0     0  4730k      0  0:00:25  0:00:13  0:00:12 4128k\n",
      " 62  116M   62 72.5M    0     0  5161k      0  0:00:23  0:00:14  0:00:09 5783k\n",
      " 71  116M   71 83.4M    0     0  5534k      0  0:00:21  0:00:15  0:00:06 7435k\n",
      " 81  116M   81 94.7M    0     0  5899k      0  0:00:20  0:00:16  0:00:04 9165k\n",
      " 90  116M   90  105M    0     0  6237k      0  0:00:19  0:00:17  0:00:02 10.3M\n",
      " 99  116M   99  116M    0     0  6473k      0  0:00:18  0:00:18 --:--:-- 10.8M\n",
      "100  116M  100  116M    0     0  6480k      0  0:00:18  0:00:18 --:--:-- 10.9M\n"
     ]
    }
   ],
   "source": [
    "!curl -L \"https://www.dropbox.com/s/m2r388lpoo7isu9/earthquakes-projected.parq\" -o \"earthquakes-projected.parq\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "874c8098",
   "metadata": {},
   "outputs": [
    {
     "ename": "ArrowMemoryError",
     "evalue": "realloc of size 16932352 failed",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mArrowMemoryError\u001b[39m                          Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m df = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_parquet\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mearthquakes-projected.parq\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      2\u001b[39m df.time = df.time.dt.tz_localize(\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m      3\u001b[39m df = df.set_index(df.time)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Ruslan\\miniconda3\\Lib\\site-packages\\pandas\\io\\parquet.py:667\u001b[39m, in \u001b[36mread_parquet\u001b[39m\u001b[34m(path, engine, columns, storage_options, use_nullable_dtypes, dtype_backend, filesystem, filters, **kwargs)\u001b[39m\n\u001b[32m    664\u001b[39m     use_nullable_dtypes = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m    665\u001b[39m check_dtype_backend(dtype_backend)\n\u001b[32m--> \u001b[39m\u001b[32m667\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mimpl\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    668\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    669\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    670\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfilters\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfilters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    671\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    672\u001b[39m \u001b[43m    \u001b[49m\u001b[43muse_nullable_dtypes\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_nullable_dtypes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    673\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdtype_backend\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype_backend\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    674\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfilesystem\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfilesystem\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    675\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    676\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Ruslan\\miniconda3\\Lib\\site-packages\\pandas\\io\\parquet.py:274\u001b[39m, in \u001b[36mPyArrowImpl.read\u001b[39m\u001b[34m(self, path, columns, filters, use_nullable_dtypes, dtype_backend, storage_options, filesystem, **kwargs)\u001b[39m\n\u001b[32m    267\u001b[39m path_or_handle, handles, filesystem = _get_path_or_handle(\n\u001b[32m    268\u001b[39m     path,\n\u001b[32m    269\u001b[39m     filesystem,\n\u001b[32m    270\u001b[39m     storage_options=storage_options,\n\u001b[32m    271\u001b[39m     mode=\u001b[33m\"\u001b[39m\u001b[33mrb\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    272\u001b[39m )\n\u001b[32m    273\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m274\u001b[39m     pa_table = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mapi\u001b[49m\u001b[43m.\u001b[49m\u001b[43mparquet\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_table\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    275\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpath_or_handle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    276\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    277\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfilesystem\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfilesystem\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    278\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfilters\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfilters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    279\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    280\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    281\u001b[39m     result = pa_table.to_pandas(**to_pandas_kwargs)\n\u001b[32m    283\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m manager == \u001b[33m\"\u001b[39m\u001b[33marray\u001b[39m\u001b[33m\"\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Ruslan\\miniconda3\\Lib\\site-packages\\pyarrow\\parquet\\core.py:1843\u001b[39m, in \u001b[36mread_table\u001b[39m\u001b[34m(source, columns, use_threads, schema, use_pandas_metadata, read_dictionary, memory_map, buffer_size, partitioning, filesystem, filters, use_legacy_dataset, ignore_prefixes, pre_buffer, coerce_int96_timestamp_unit, decryption_properties, thrift_string_size_limit, thrift_container_size_limit, page_checksum_verification)\u001b[39m\n\u001b[32m   1831\u001b[39m     \u001b[38;5;66;03m# TODO test that source is not a directory or a list\u001b[39;00m\n\u001b[32m   1832\u001b[39m     dataset = ParquetFile(\n\u001b[32m   1833\u001b[39m         source, read_dictionary=read_dictionary,\n\u001b[32m   1834\u001b[39m         memory_map=memory_map, buffer_size=buffer_size,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1840\u001b[39m         page_checksum_verification=page_checksum_verification,\n\u001b[32m   1841\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m1843\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdataset\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_threads\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_threads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1844\u001b[39m \u001b[43m                    \u001b[49m\u001b[43muse_pandas_metadata\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_pandas_metadata\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Ruslan\\miniconda3\\Lib\\site-packages\\pyarrow\\parquet\\core.py:1485\u001b[39m, in \u001b[36mParquetDataset.read\u001b[39m\u001b[34m(self, columns, use_threads, use_pandas_metadata)\u001b[39m\n\u001b[32m   1477\u001b[39m         index_columns = [\n\u001b[32m   1478\u001b[39m             col \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m _get_pandas_index_columns(metadata)\n\u001b[32m   1479\u001b[39m             \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(col, \u001b[38;5;28mdict\u001b[39m)\n\u001b[32m   1480\u001b[39m         ]\n\u001b[32m   1481\u001b[39m         columns = (\n\u001b[32m   1482\u001b[39m             \u001b[38;5;28mlist\u001b[39m(columns) + \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mset\u001b[39m(index_columns) - \u001b[38;5;28mset\u001b[39m(columns))\n\u001b[32m   1483\u001b[39m         )\n\u001b[32m-> \u001b[39m\u001b[32m1485\u001b[39m table = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_dataset\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto_table\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1486\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mfilter\u001b[39;49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_filter_expression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1487\u001b[39m \u001b[43m    \u001b[49m\u001b[43muse_threads\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_threads\u001b[49m\n\u001b[32m   1488\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1490\u001b[39m \u001b[38;5;66;03m# if use_pandas_metadata, restore the pandas metadata (which gets\u001b[39;00m\n\u001b[32m   1491\u001b[39m \u001b[38;5;66;03m# lost if doing a specific `columns` selection in to_table)\u001b[39;00m\n\u001b[32m   1492\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m use_pandas_metadata:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Ruslan\\miniconda3\\Lib\\site-packages\\pyarrow\\_dataset.pyx:574\u001b[39m, in \u001b[36mpyarrow._dataset.Dataset.to_table\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Ruslan\\miniconda3\\Lib\\site-packages\\pyarrow\\_dataset.pyx:3865\u001b[39m, in \u001b[36mpyarrow._dataset.Scanner.to_table\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Ruslan\\miniconda3\\Lib\\site-packages\\pyarrow\\error.pxi:155\u001b[39m, in \u001b[36mpyarrow.lib.pyarrow_internal_check_status\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Ruslan\\miniconda3\\Lib\\site-packages\\pyarrow\\error.pxi:92\u001b[39m, in \u001b[36mpyarrow.lib.check_status\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mArrowMemoryError\u001b[39m: realloc of size 16932352 failed"
     ]
    }
   ],
   "source": [
    "df = pd.read_parquet(\"earthquakes-projected.parq\")\n",
    "df.time = df.time.dt.tz_localize(None)\n",
    "df = df.set_index(df.time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da6d1333",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea1fc8d5",
   "metadata": {},
   "source": [
    "Чтобы сравнить подходы HoloViz с другими, мы возьмем подвыборку (1%) из большого набора данных для дальнейшей обработки любым инструментом:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72acb7e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "small_df = df.sample(frac=0.01)\n",
    "print(small_df.shape)\n",
    "small_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f5f9076",
   "metadata": {},
   "source": [
    "Мы будем переключаться между small_df и df в зависимости от того, работает ли метод, который мы показываем, только для небольших наборов данных, или его можно использовать для любого набора."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5eb65a7",
   "metadata": {},
   "source": [
    "## Использование Pandas `.plot()`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "608b2692",
   "metadata": {},
   "source": [
    "Первое, что мы хотели бы сделать с этими данными, - это визуализировать места с землетрясениями. Итак, мы хотели бы построить диаграмму рассеяния, где x - долгота, а y - широта.\n",
    "\n",
    "Мы можем это сделать для небольшого фрейма данных, используя API `pandas.plot` и Matplotlib:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8240326",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d102233c",
   "metadata": {},
   "outputs": [],
   "source": [
    "small_df.plot.scatter(x=\"longitude\", y=\"latitude\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0447cb9b",
   "metadata": {},
   "source": [
    "### Упражнение:\n",
    "\n",
    "Попробуйте заменить inline на widget и посмотрите, какие интерактивные возможности доступны в Matplotlib. В некоторых случаях вам может потребоваться перезагрузить страницу и перезапустить блокнот, чтобы она отображалась правильно."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af9987a4",
   "metadata": {},
   "source": [
    "## Использование .hvplot\n",
    "\n",
    "Как вы могли увидеть выше, Pandas API легко строит график, где вы можете посмотреть структуру краев тектонических плит, которые во многих случаях соответствуют визуальным краям континентов (например, западная сторона Африки, в центре). Вы можете создать очень похожий график с теми же аргументами, используя hvplot, после импорта `hvplot.pandas` для поддержки hvPlot в Pandas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a505d164",
   "metadata": {},
   "outputs": [],
   "source": [
    "small_df.hvplot.scatter(x=\"longitude\", y=\"latitude\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f4df58e",
   "metadata": {},
   "source": [
    "Здесь, в отличие от Pandas `.plot()`, есть действие по умолчанию при наведении курсора на точки данных, чтобы показать значения местоположения, и вы всегда можете панорамировать и масштабировать, чтобы сосредоточиться на любой конкретной области интересующих данных. Масштабирование и панорамирование также работают, если вы используете бэкэнд Matplotlib `widget`.\n",
    "\n",
    "Вы могли заметить, что многие точки в только что созданном графике лежат друг на друге. Это называется [\"overplotting\"](https://datashader.org/user_guide/Plotting_Pitfalls.html), и его можно избежать разными способами, например, сделав точки слегка прозрачными или объединяя данные."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91757cc4",
   "metadata": {},
   "source": [
    "### Упражнение №1\n",
    "\n",
    "Попробуйте изменить `alpha`, установив значение 0.1 на графике выше, чтобы увидеть эффект этого подхода."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb7bd43d",
   "metadata": {},
   "source": [
    "$\\texttt{pythonsmall}_{d}{f.hvplot.scaer}(x = \\text{'longitude'}, y = \\text{'latitude'}, a = 0.1)_{d}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "047d088e",
   "metadata": {},
   "outputs": [],
   "source": [
    "small_df.hvplot.scatter(x=\"longitude\", y=\"latitude\", alpha=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "238d58aa",
   "metadata": {},
   "source": [
    "Попробуйте создать график hexbin."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b3916c6",
   "metadata": {},
   "source": [
    "$$\\text{pythonsmall}_qf.\\text{hvplot.hexb} \\in (x = \\text{'longitude'}, y = \\text{'latitude'})$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8adac45c",
   "metadata": {},
   "outputs": [],
   "source": [
    "small_df.hvplot.hexbin(x=\"longitude\", y=\"latitude\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5b56bc9",
   "metadata": {},
   "source": [
    "## Получение справки\n",
    "\n",
    "Как можно узнать о ключевом аргументе `alpha` в первом упражнении или как вы можете узнать обо всех опциях, доступных с `hvplot`. Для этого вы можете использовать завершение табуляции в Jupyter блокноте или функцию `hvplot.help`, которые описаны в руководстве пользователя.\n",
    "\n",
    "Для завершения табуляции вы можете нажать табуляцию после открывающей скобки в вызове `obj.hvplot.<kind>(`. Например, вы можете попробовать нажать табуляцию после частичного выражения `small_df.hvplot.scatter(<TAB>`.\n",
    "\n",
    "Кроме того, вы можете вызвать `hvplot.help(<kind>)`, чтобы увидеть всплывающую панель документации в блокноте.\n",
    "\n",
    "Попробуйте раскомментировать следующую строку и выполнить ее:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4b5211d",
   "metadata": {},
   "outputs": [],
   "source": [
    "hvplot.help(\"scatter\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10a7dc66",
   "metadata": {},
   "source": [
    "Вы увидите, что есть много вариантов! Вы можете контролировать, какой раздел документации просматриваете, с помощью логических переключателей `generic`, `docstring` и `style`, также задокументированных в [руководстве пользователя](https://hvplot.holoviz.org/user_guide/Customization.html). Если вы запустите следующую ячейку, вы увидите, что `alpha `указана в 'Style options'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f108bb1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "hvplot.help(\"scatter\", style=True, generic=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6a82c75",
   "metadata": {},
   "source": [
    "Эти параметры стиля относятся к параметрам, которые являются частью Bokeh API. Это означает, что ключевое слово `alpha` передается непосредственно в Bokeh, как и все другие стилевые параметры. Поскольку это параметры уровня Bokeh, вы можете узнать больше, воспользовавшись функцией поиска в [документации Bokeh](https://docs.bokeh.org/en/latest/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfc30807",
   "metadata": {},
   "outputs": [],
   "source": [
    "hvplot.help(\"scatter\", style=True, generic=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa053205",
   "metadata": {},
   "source": [
    "## Datashader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8911bd14",
   "metadata": {},
   "source": [
    "Часто приходится производить выбор еще до того, как вы понимаете свойства данных, например, выбор alpha-значения или размера ячейки для агрегирования. Такие предположения могут склонить вас к определенным аспектам данных, и, конечно же, необходимость выбросить 99% данных может скрыть закономерности, которые вы могли бы увидеть в ином случае. Для первоначального исследования нового набора данных гораздо безопаснее, если вы можете просто **просмотреть** данные, прежде чем делать какие-либо предположения о его форме или структуре, и без необходимости подвыборки.\n",
    "\n",
    "Чтобы избежать некоторых проблем традиционных диаграмм рассеяния, мы можем использовать поддержку [Datashader](https://datashader.org/). Datashader объединяет данные в каждый пиксель без каких-либо произвольных настроек параметров, делая ваши данные видимыми немедленно, прежде чем вы узнаете, чего от них ожидать. В **hvplot** мы можем активировать эту возможность, установив **rasterize=True** для вызова Datashader перед рендерингом и **cnorm='eq_hist'** ([\"выравнивание гистограммы\"](https://datashader.org/user_guide/Plotting_Pitfalls.html)), чтобы указать, что цветовое отображение должно адаптироваться к любому распределению данных:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3a98d70",
   "metadata": {},
   "outputs": [],
   "source": [
    "small_df.hvplot.scatter(x=\"longitude\", y=\"latitude\", rasterize=True, cnorm=\"eq_hist\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7aaf1bb",
   "metadata": {},
   "source": [
    "Мы уже можем видеть гораздо больше деталей, но помните, что мы все еще наносим на график только 1% данных (21 тыс. землетрясений). С помощью Datashader мы можем быстро и легко построить полный исходный набор данных о 2,1 млн землетрясений:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dadca0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.hvplot.scatter(\n",
    "    x=\"longitude\", y=\"latitude\", rasterize=True, cnorm=\"eq_hist\", dynspread=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87db0b37",
   "metadata": {},
   "source": [
    "Здесь вы можете увидеть все подробности из миллионов мест землетрясений. Если у вас запущен блокнот, вы можете увеличивать масштаб и видеть дополнительные детали на каждом уровне масштабирования без настройки каких-либо параметров или каких-либо предположений о форме или структуре данных.\n",
    "\n",
    "Вы можете указать цветовое отображение **cnorm='log'** или значение по умолчанию **cnorm='linear'**, которые легче интерпретировать, но хорошей практикой является **cnorm='eq_hist'**, чтобы увидеть форму данных, прежде чем перейти к более простой для интерпретации, но потенциально скрывающей данные цветовой карте.\n",
    "\n",
    "Вы можете узнать больше о Datashader на [datashader.org](https://datashader.org/) или на [странице Datashader на holoviews.org](https://holoviews.org/user_guide/Large_Data.html). На данный момент самое важное, что нужно знать об этом, это то, что Datashader позволяет нам удобно работать с произвольно большими наборами данных в веб-браузере."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9aa211e",
   "metadata": {},
   "source": [
    "Упражнение\n",
    "Выберите подмножество данных, например только magitude >5 и нанесите их на другую цветовую карту (допустимые значения **cmap** включают 'viridis_r', 'Reds' и 'magma_r'):"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29b8fac7",
   "metadata": {},
   "source": [
    "$$\\texttt{pythondf[df.mag>5].hvplot.scaer}(x=\\text{'longitude'}, y=\\text{'latitude'}, \\text{datashade}=\\text{True}, \\text{cmap}=\\text{'Reds'})$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07ff090d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.mag > 5].hvplot.scatter(x=\"longitude\", y=\"latitude\", rasterize=True, cmap=\"Reds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4afaa7ac",
   "metadata": {},
   "source": [
    "# Статистические графики"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fe05726",
   "metadata": {},
   "source": [
    "Давайте углубимся в некоторые другие возможности `.plot()` и `.hvplot()`, начиная с частоты землетрясений разной магнитуды."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd5ea5c0",
   "metadata": {},
   "source": [
    "| Величина | Эффект землетрясения | Расчетное количество каждый год |\n",
    "|----------|----------------------|----------------------------------|\n",
    "| 2,5 или менее | Обычно не ощущается, но может быть зафиксировано сейсмографом. | 900,000 |\n",
    "| от 2,5 до 5,4 | Часто ощущается, но вызывает лишь незначительные повреждения. | 30,000 |\n",
    "| от 5,5 до 6,0 | Незначительные повреждения зданий и других построек. | 500 |\n",
    "| от 6,1 до 6,9 | Может нанести большой ущерб густонаселенным районам. | 100 |\n",
    "| от 7,0 до 7,9 | Сильное землетрясение. Серьезный ущерб. | 20 |\n",
    "| 8,0 или выше | Великое землетрясение. Может полностью разрушить сообщества вблизи эпицентра. Один раз в 5–10 лет | — |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05432e15",
   "metadata": {},
   "source": [
    "В качестве первого прохода мы будем использовать гистограмму сначала с `.plot.hist`, затем с `.hvplot.hist`. Перед построением графика мы можем очистить данные, заменив любую величину меньше 0 на NaN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9acceac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_df = df.copy()\n",
    "cleaned_df[\"mag\"] = df.mag.where(df.mag > 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c775bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_df.plot.hist(y=\"mag\", bins=50);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48058d1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.hvplot.hist(y=\"mag\", bin_range=(0, 10), bins=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b7ae2a0",
   "metadata": {},
   "source": [
    "# Упражнение\n",
    "Создайте график ядерной оценки плотности (kde) величины для cleaned_df:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f851983a",
   "metadata": {},
   "source": [
    "$$\\texttt{pythonc} \\leq a \\neq \\texttt{d}_{d}{f.hvplot.kde}(y = \\text{'mag'})$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42c64c83",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_df.hvplot.kde(y=\"mag\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "661cf814",
   "metadata": {},
   "source": [
    "Категориальные переменные\n",
    "Далее мы классифицируем землетрясения по глубине. Вы можете прочитать обо всех переменных, доступных в этом наборе данных [здесь](https://earthquake.usgs.gov/data/comcat/data-eventterms.php). Согласно [странице USGS о глубинах землетрясений](https://earthquake.usgs.gov/data/comcat/data-eventterms.php), типичная глубина по категориям:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ccf8d37",
   "metadata": {},
   "source": [
    "| Класс глубины | Глубина | \n",
    "|----------|--------------|\n",
    "| мелкий | 0 - 70 км |\n",
    "| средний | 70 - 300 км |\n",
    "| глубокий | 300 - 700 км |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d73d3a0",
   "metadata": {},
   "source": [
    "Сначала мы воспользуемся `pd.cut`, чтобы разделить `small_dataset` на категории глубины."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad45efe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "depth_bins = [-np.inf, 70, 300, np.inf]\n",
    "depth_names = [\"Shallow\", \"Intermediate\", \"Deep\"]\n",
    "depth_class_column = pd.cut(cleaned_df[\"depth\"], depth_bins, labels=depth_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a335966f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_df.insert(1, \"depth_class\", depth_class_column)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7741de3e",
   "metadata": {},
   "source": [
    "Теперь мы можем использовать новую категориальную переменную для группировки данных. Сначала мы наложим все группы на один и тот же график, используя опцию `by`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15f9abc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_df.hvplot.hist(y=\"mag\", by=\"depth_class\", alpha=0.6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "899a3825",
   "metadata": {},
   "source": [
    "ПРИМЕЧАНИЕ: Нажмите на легенду, чтобы отключить определенные категории и посмотреть, что за ними скрывается."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6a56ed2",
   "metadata": {},
   "source": [
    "Упражнение\n",
    "Добавьте `subplots=True` и `width=300`, чтобы увидеть разные классы рядом, а не наложенными. Оси будут связаны, поэтому попробуйте увеличить."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "929f40bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_df.hvplot.hist(y=\"mag\", by=\"depth_class\", subplots=True, width=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "877388cc",
   "metadata": {},
   "source": [
    "## Группировка"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a60be533",
   "metadata": {},
   "source": [
    "Что, если вам нужен один график, но вы хотите увидеть каждый класс отдельно? Вы можете использовать опцию `groupby`, чтобы получить виджет для переключения между классами, здесь, на двумерном графике (использование подмножества данных в качестве двумерных графиков может быть дорогостоящим для вычисления):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fe4a0bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_small_df = cleaned_df.sample(frac=0.01)\n",
    "cleaned_small_df.hvplot.bivariate(x=\"mag\", y=\"depth\", groupby=\"depth_class\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6971aa6",
   "metadata": {},
   "source": [
    "Помимо классификации по глубине, мы можем классифицировать по величине."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13574ee0",
   "metadata": {},
   "source": [
    "| Класс магнитуды | Величина | \n",
    "|----------|--------------|\n",
    "| Great | 8 or more |\n",
    "| Major | 7 - 7.9 |\n",
    "| Strong | 6 - 6.9 |\n",
    "| Moderate | 5 - 5.9 |\n",
    "| Light | 4 - 4.9 |\n",
    "| Minor | 3 - 3.9 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2f08e26",
   "metadata": {},
   "outputs": [],
   "source": [
    "classified_df = df[df.mag >= 3].copy()\n",
    "\n",
    "depth_class = pd.cut(classified_df.depth, depth_bins, labels=depth_names)\n",
    "\n",
    "classified_df[\"depth_class\"] = depth_class\n",
    "\n",
    "mag_bins = [2.9, 3.9, 4.9, 5.9, 6.9, 7.9, 10]\n",
    "mag_names = [\"Minor\", \"Light\", \"Moderate\", \"Strong\", \"Major\", \"Great\"]\n",
    "mag_class = pd.cut(classified_df.mag, mag_bins, labels=mag_names)\n",
    "classified_df[\"mag_class\"] = mag_class\n",
    "\n",
    "categorical_df = classified_df.groupby([\"mag_class\", \"depth_class\"]).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8feb6848",
   "metadata": {},
   "source": [
    "Теперь, когда мы разделили данные на две категории, мы можем использовать логарифмическую тепловую карту, чтобы визуально представить эти данные как количество обнаруженных землетрясений в каждой комбинации классов глубины и магнитуды:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e26f689d",
   "metadata": {},
   "source": [
    "# Дальнейшие исследования"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c0b99d8",
   "metadata": {},
   "source": [
    "Как видите, hvPlot упрощает интерактивное исследование данных с помощью команд, основанных на широко используемом API Pandas `.plot ()`, но теперь поддерживает гораздо больше функций и различные типы данных. Приведенные выше визуализации касаются лишь поверхности того, что доступно на hvPlot, и вы можете изучить [веб-сайт hvPlot](https://hvplot.holoviz.org/en/docs/latest/), чтобы увидеть гораздо больше, или просто изучить его самостоятельно, используя завершение табуляции (`df.hvplot`.[TAB])."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
