{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Файл лога, в котором фиксируются пройденный материал.\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "27/01/25\n",
    "\n",
    "1. Создала аккаунт на GitHub и оформила его, использовав примеры из шаблонов.\n",
    "2. Создала аккаунт на Kaggle и получила статус контрибьютора.\n",
    "3. Создала аккаунт на ODS.AI.\n",
    "4. Скачала и установила GitHub Desktop и Cursor, проверила настройки ранее установленного VS Code.\n",
    "5. Установила плагины, настроила Cursor и VS Code к работе.\n",
    "6. Установила CPython, Git и Conda.\n",
    "7. Создала джамборд для учебы в canva.\n",
    "8. Склонировала репозиторий, присоединилась к команде и создала свою ветку.\n",
    "9. Запустила проверку файлов в репозитории командой pre-commit run --all-files.\n",
    "10. Ознакомилась с процессом принятия и отправки коммитов."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "27/01/25\n",
    "\n",
    "1. Введение в линейную регрессию. \n",
    "- 1.1 Метод наименьших квадратов применяется для подбора коэфициентов в линейной регрессии (он оценивает параметры регрессии). \n",
    "- 1.2 если данные поддаются линейным взаимосвязям, то мы можем применять линейную модель. \n",
    "2. Машинное обучение. 2 большие группы - с учителем и без учителя. \n",
    "- 2.1 Обучение с учителем: а) регрессионные модели и б) классификационные. \n",
    "- 2.2 Без учителя: кластеризация. \n",
    "3. Рассмотрели порядок обучения модели. \n",
    "4. Закон нормального распределения. \n",
    "- 4.1 Описывает, как часто различные значения случайной величины встречаются в наборе данных. \n",
    "- 4.2 Математическое ожидание — это среднее значение случайной величины. \n",
    "- 4.3 PDF - график плотности случайной величины. \n",
    "5. Метод наименьших квадратов (для подбора весов). \n",
    "- 5.1 Его задача - минимизировать сумму квадратов регрессионных остатков. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "02/02/25\n",
    "\n",
    "1. Теорема Гаусса Маркова: МНК является лучшей линейной несмещенной оценкой. \n",
    "- 1.1 Несмещенная модель. Суть: когда мы можем взять какое-то подмножество точек из целого множества, и математическое ожидание этого подмножества будет совпадать с таковым у самого множества. \n",
    "- 1.2 Гомоскедастичность - свойство, означающее постоянство условной дисперсии вектора или последовательности случайных величин. Означает одинаковый разброс величин относительно нашей линии фита. \n",
    "\n",
    "- Как наглядно выглядят гомоскедастичность и гетероскедастичность:\n",
    "![Гетероскедастичность](https://myslide.ru/documents_3/2b677335f0177d29121e558fe4d3215c/img3.jpg)\n",
    "\n",
    "2. Математическое ожидание. \n",
    "3. Понятие дисперсии и стандартного отклонения. Если дисперсия фиксирована и не зависит от входных данных, такая модель называется гомоскедастической регрессией, а если зависит - гетероскедастической. \n",
    "4. Понятия средняя, медиана и мода. \n",
    "- 4.1 Робастная оценка - это и есть медиана, устойчива к выбросам. \n",
    "- 4.2 Среднее - сумма всех значений деленная на количество этих значений. \n",
    "- 4.2 Медиана - значение, которое делит отсортированный набор на две равные части. \n",
    "- 4.3 Мода - значение, которое встречается в выборке чаще всего. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "03/02/25\n",
    "\n",
    "1. Задача обучения модели - найти такой алгоритм А (решающую функцию), приближающую у на всем множестве Х. То есть мы хотим найти функцию, которая сможет апроксимировать - даст максимальное приближение к истинному алгоритму. \n",
    "2. Признаки объекта. Типы признаков. \n",
    "3. Функция потерь. Эмпирический риск. Минимизация эмпирического риска. \n",
    "4. Функция потерь. \n",
    "5. Градиент - это вектор частных производных, который показывает направление наискорейшего роста. Антиградиент. \n",
    "6. Learning rate - шаг, с какой скоростью мы хотим обучать модель. Подбирается до обучения модели. \n",
    "7. Геометрический смысл частных производных функции двух переменных. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "07/02/25\n",
    "\n",
    "1. Функция потерь. MSE. \n",
    "2. Взятие производной по каждой переменной в функции потерь путем блокировки (заморозки) других переменных в этой функции. \n",
    "3. Градиент - производная по нескольким переменным.\n",
    "4. Градиент по сути это направление наискорейшего роста функции, поэтому мы берем антиградиент, так как нам нужно добраться до глобального минимума. \n",
    "5. Задача оптимизации - найти глобальный минимум функции потерь.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10/02/25\n",
    "\n",
    "1. Градиент - это вектор частных производных. Векторная форма записи градиента. \n",
    "2. Понятие одномерной и многомерной линейно регрессии. \n",
    "3. Средняя абсолютная ошибка (MAE). Отличие МАЕ от MSE. \n",
    "4. Learning rate. Градиентный спуск. Learning rate отвечает за шаг градиентного спуска вниз. Learning rate подбирается до обучения. \n",
    "5. Взятие частной производной от функции MAE. \n",
    "6. Субградиент - это вектор. Множество субградиентов называется субдифференциал. \n",
    "7. Проблема производной MAE - неопределенность в нуле. \n",
    "8. Функция знака - альтернативная функция, которая похожа на производную MAE и определена в нуле. Ее мы будем использовать в python. \n",
    "9. Вместо использование функции знака, в качестве второго подхода можно использовать доопределение функции. \n",
    "10. Способы поиска коэфициентов регрессии: итерационный (с помощью градиентного способа) и аналитический. \n",
    "11. Аналитический способ - самый точный способ для поиска коэфициентов. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "14/02/25\n",
    "\n",
    "1. Экзамен по функции потерь и производным. \n",
    "2. Аналитический способ решения МНК. \n",
    " - RSS - Residual Sum of Squares - сумма квадратов остатков. \n",
    " - Взятие частных производных. \n",
    " - Решение системы уравнений. \n",
    "3. Аналитическое решение является самым точным из всех. Но если будет очень много переменных х (фич), то процесс нахождения весов будет достаточно долгим. \n",
    "4. Вычисление аналитическим методом на примере задачи размерах и продажах торговой точки с 5 магазинами. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "17/02/25\n",
    "\n",
    "## Реализация линейной регрессии и функции потерь на python. \n",
    "1. Библиотеки, которые нам понадобятся для вычислений: \n",
    " - numpy \n",
    " - pandas \n",
    " - matplotlib \n",
    " - math \n",
    " - sympy (для работы с символьными вычислениями) \n",
    "2. Понятие критерия остановы. \n",
    "3. Для того, чтобы осуществить итеративный поиск весов, необходимо задать learning rate и количество итераций. Как только разница между двумя значениями весов будет меньше epsilon (который мы тоже задаем сами), нам следует остановиться в поиске минимума. \n",
    "4. Epsilon подбирается в зависимости от задачи. \n",
    "5. Моделирование на python. Создание датафрейма и визуализация точек с на графике. Подключение библиотек: \n",
    " - import numpy as np \n",
    " - import matplotlib.pyplot as plt \n",
    " - import pandas as pd "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SENATOROV",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
