{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"Lessons log.\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 04.02.2025\n",
    "Repository initialization, first commit and push"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 26.02.2025\n",
    "- Data processing workflow\n",
    "- Understanding Linear Regression\n",
    "  - One dimensional linear regression\n",
    "  - Best fit line\n",
    "  - Derivative definition\n",
    "  - Norms\n",
    "    - L1 norm, also known as the Manhattan norm\n",
    "    - L2 norm, also known as the Euclidean norm\n",
    "  - Smooth vs. Non-Smooth Functions\n",
    "  - Functional Loss\n",
    "  - Numerical method(iterations) in finding coefficients\n",
    "  - Definition of predictor(feature, independent) and target(dependent) variables\n",
    "  - Hypothesis function\n",
    "    - Liniarity\n",
    "    - Independence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "source": [
    "### 05.03.2025\n",
    "\n",
    "- Road map for Linear Regression\n",
    "  - Introduction\n",
    "    - Definition\n",
    "    - Types of Linear Regressions\n",
    "      - Simple\n",
    "      - Multiple\n",
    "  - Basic definitions\n",
    "    - Variables\n",
    "      - target - dependent variable\n",
    "      - feature - independent variable\n",
    "    - Linear Regression Equation\n",
    "      - Simple\n",
    "      - Multiple\n",
    "    - Hypothesis\n",
    "  - Estimation of model parameters\n",
    "    - Ordinary Least Squares\n",
    "    - Gradient Descent\n",
    "  - Model quality estimation\n",
    "    - Metrics\n",
    "      - MAE (Mean Absolute Error)\n",
    "      - MSE (Mean Squared Error)\n",
    "      - RMSE (Root Mean Squared Error)\n",
    "      - R² (Коэффициент детерминации)\n",
    "  - Checking the Assumptions of Linear Regression\n",
    "    - Linearity of the relationship\n",
    "    - Normality of residuals\n",
    "    - Homoscedasticity\n",
    "    - Absence of multicollinearity between independent variables\n",
    "  - Problems and solutions\n",
    "    - Overfitting\n",
    "      - Regularization L1 and L2\n",
    "    - Underfitting\n",
    "      -  Add more features and use more complicated model\n",
    "    - Multicollinearity\n",
    "      - Removing correlated variables or using regularization (Ridge, Lasso)\n",
    "  - Regularization\n",
    "    - Ridge (L2)\n",
    "    - Lasso (L1)\n",
    "    - Elastic Net (L1 + L2)\n",
    "  - Advanced\n",
    "    - Multiple Linear Regression — with multiple predictors.\n",
    "    - Polynomial Regression — nonlinear relationships.\n",
    "    - Regularization (Ridge, Lasso, Elastic Net).\n",
    "    - Feature Scaling — StandardScaler, MinMaxScaler.\n",
    "    - Checking Assumptions using Residual Plots and QQ-Plots.\n",
    "\n",
    "- Machine learning\n",
    "  - Supervised\n",
    "    - Regression\n",
    "    - Classification\n",
    "  - Unsupervised\n",
    "    - Clustering\n",
    "\n",
    "\n",
    "- Classification of Regression Models\n",
    "\n",
    "    - Regression\n",
    "        - By Number of Factors\n",
    "            - Simple (Pairwise) Regression\n",
    "            - Multiple Regression          \n",
    "        - By Relationship Type\n",
    "            - Linear\n",
    "            - Nonlinear\n",
    "                - Linear by Variables\n",
    "                - Linear by Parameters\n",
    "                - Internally Nonlinear\n",
    "\n",
    "\n",
    "- Nonlinear functions\n",
    "  - Power Function Model – Used for dependencies with constant elasticity.\n",
    "  - Exponential Model – Used for processes with a constant growth rate.\n",
    "  - Logarithmic Model – Used for dependencies with a constant decrease in increment.\n",
    "  - Hyperbolic Model – Used for dependencies with a lower or upper limit.\n",
    "  - Polynomial Model of Different Degrees – Used for relationships with changing direction.\n",
    "\n",
    "- Steps for Building a Model\n",
    "- Probabilistic and non-probabilistic or deterministic approaches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 12.03.2025\n",
    "\n",
    "- Time complexity and space for analytic and iterative approaches\n",
    "- Method of finding parameters:\n",
    "  - Analytic(Linear algebra)\n",
    "    - Pros/Con\n",
    "    - Main definition\n",
    "    - Equation\n",
    "  - Iterative(Calculus)\n",
    "    - Pros/Con\n",
    "    - Main definition\n",
    "    - Equation\n",
    "- Loss function and derivative\n",
    "- Calculate derivative\n",
    "  - Graphical approach\n",
    "  - Algebraic approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 19.03.2025\n",
    "\n",
    "- Concepts of Derivatives\n",
    "    - Definition of a Derivative\n",
    "    - Rules for Computing Derivatives\n",
    "      - Power Function\n",
    "      - Scalar\n",
    "      - Product Rule\n",
    "      - Quotient Rule\n",
    "      - Complex Function (Composition of Functions)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 24.03.2025\n",
    "\n",
    "- Python practice\n",
    "  - Finding derivatives with the help of `sympy` module\n",
    "  - Optimization of a function and finding the minimum\n",
    "  - Building plots to represent decreasing loss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11.04.2025 \n",
    "- Function of several variables\n",
    "- Gradient concept\n",
    "- Taking partial derivatives\n",
    "- Gradient descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 16.04.2025\n",
    "\n",
    "- Projection of a vector onto a vector\n",
    "- Scalar product of vectors\n",
    "- Scalar product of vectors in Python\n",
    "- Geometric meaning of the derivative in the direction of two variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 23.04.2025\n",
    "\n",
    "- Geometric meaning of directional derivatives\n",
    "- Geometric meaning of partial derivatives\n",
    "- Gradient of a function\n",
    "- Practice of finding directional derivative and gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 30.04.2025\n",
    "- Gradient of a function\n",
    "- Directional derivative\n",
    "- Practice of finding directional derivative and gradient"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
