{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Stream input/output. Working with text files. JSON.\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read from stdin\n",
    "\n",
    "```python\n",
    "from sys import stdin\n",
    "\n",
    "lines = []\n",
    "for line in stdin:\n",
    "    lines.append(line)\n",
    "print(lines)\n",
    "```\n",
    "\n",
    "### Read from stdin and rstrip new line\n",
    "\n",
    "```python\n",
    "from sys import stdin\n",
    "\n",
    "lines = []\n",
    "for line in stdin:\n",
    "    lines.append(line.rstrip(\"\\n\"))\n",
    "print(lines)\n",
    "```\n",
    "\n",
    "\n",
    "### Alternative method tp read from stdin, it keeps new lines\n",
    "\n",
    "```python\n",
    "from sys import stdin\n",
    "\n",
    "lines = stdin.readlines()\n",
    "print(lines)\n",
    "```\n",
    "\n",
    "### Read stdin in one string\n",
    "\n",
    "```python\n",
    "from sys import stdin\n",
    "\n",
    "text = stdin.read()\n",
    "print([text])\n",
    "```\n",
    "\n",
    "\n",
    "In Python, the built-in `open()` function is used for file operations. Key arguments include:\n",
    "\n",
    "- file: Path to the file (absolute or relative).\n",
    "mode: Access mode:\n",
    "    - \"r\": Read (default).\n",
    "    - \"w\": Write (creates a new file).\n",
    "    - \"a\": Append (creates file if it doesn’t exist).\n",
    "    - \"+\": Allows both reading and writing.\n",
    "- encoding: Specifies file encoding (e.g., \"UTF-8\").\n",
    "To read a UTF-8 encoded text file, ensure the file is saved with UTF-8 encoding.\n",
    "\n",
    "```python\n",
    "file_in = open(\"input_1.txt\", encoding=\"UTF-8\")\n",
    "for line in file_in:\n",
    "    print(line)\n",
    "file_in.close()\n",
    "```\n",
    "\n",
    "\n",
    "After working with a file in Python, it must be closed using the close()\n",
    "method to free system resources. If not closed, the file may remain inaccessible to other programs.\n",
    "To ensure proper closure, use the context manager (with statement),\n",
    "which automatically closes the file, even if an error occurs:\n",
    "\n",
    "```python\n",
    "with open(\"input_1.txt\", encoding=\"UTF-8\") as file_in:\n",
    "    for line in file_in:\n",
    "        print(line.rstrip(\"\\n\"))\n",
    "```\n",
    "\n",
    "To write to a file in Python, you must first open it in write (\"w\") or append (\"a\") mode.\n",
    "The `write()` method is used to write data from a string variable to the file. Example:\n",
    "\n",
    "```python\n",
    "with open(\"output_1.txt\", \"w\", encoding=\"UTF-8\") as file_out:\n",
    "    n = file_out.write(\"Это первая строка\\nА вот и вторая\\nИ третья — последняя\\n\")\n",
    "print(n)\n",
    "```\n",
    "\n",
    "To write lines, `writelines` method is used.\n",
    "\n",
    "```python\n",
    "lines = [\"Это первая строка\\n\", \"А вот и вторая\\n\", \"И третья — последняя\\n\"]\n",
    "with open(\"output_2.txt\", \"w\", encoding=\"UTF-8\") as file_out:\n",
    "    file_out.writelines(lines)\n",
    "```\n",
    "\n",
    "To read JSON files in Python, use the json.load() method,\n",
    "which loads the entire JSON file and returns a corresponding\n",
    "Python data structure (e.g., dictionary or list).\n",
    "\n",
    "```python\n",
    "import json\n",
    "from pprint import pprint\n",
    "\n",
    "with open(\"data.json\", encoding=\"UTF-8\") as file_in:\n",
    "    records = json.load(file_in)\n",
    "pprint(records)\n",
    "```\n",
    "\n",
    "\n",
    "To write modified data back to a JSON file in Python, use the `json.dump()` method. Important arguments include:\n",
    "\n",
    "- ensure_ascii:\n",
    "    True (default) → Non-ASCII characters are stored as Unicode escape sequences (\\uXXXX).\n",
    "    False → Stores characters as they are (useful for non-Latin scripts like Russian).\n",
    "\n",
    "- indent:\n",
    "    None (default) → Writes JSON in a single line.\n",
    "    Number (e.g., 4) → Formats JSON with that many spaces for readability.\n",
    "\n",
    "- sort_keys:\n",
    "    True → Sorts dictionary keys alphabetically.\n",
    "    False (default) → Keeps original order.\n",
    "\n",
    "```python\n",
    "import json\n",
    "\n",
    "with open(\"data.json\", encoding=\"UTF-8\") as file_in:\n",
    "    records = json.load(file_in)\n",
    "records[1][\"group_number\"] = 2\n",
    "with open(\"data.json\", \"w\", encoding=\"UTF-8\") as file_out:\n",
    "    json.dump(records, file_out, ensure_ascii=False, indent=2)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1\n",
    "\n",
    "import json\n",
    "import os\n",
    "import sys\n",
    "from sys import stdin\n",
    "\n",
    "total: int = 0\n",
    "\n",
    "for input_val in stdin:\n",
    "    total += sum(map(int, input_val.split(\" \")))\n",
    "print(total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2\n",
    "\n",
    "\n",
    "avrg_before: int = 0\n",
    "avrg_after: int = 0\n",
    "pupils_count: int = 0\n",
    "\n",
    "for pupil_line in stdin:\n",
    "    avrg_before += int(pupil_line.split(\" \")[1])\n",
    "    avrg_after += int(pupil_line.split(\" \")[2])\n",
    "    pupils_count += 1\n",
    "height_diff = round(avrg_after / pupils_count - avrg_before / pupils_count)\n",
    "print(height_diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3\n",
    "\n",
    "\n",
    "for program_line in stdin:\n",
    "    comment_start_index = program_line.find(\"#\")\n",
    "\n",
    "    if comment_start_index != -1:\n",
    "        cleaned_program_line = program_line[:comment_start_index]\n",
    "        if cleaned_program_line.strip():\n",
    "            print(cleaned_program_line)\n",
    "    else:\n",
    "        print(program_line, end=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 4\n",
    "\n",
    "\n",
    "title_lines = stdin.readlines()\n",
    "\n",
    "titles = title_lines[:-1]\n",
    "query = title_lines[-1].strip()\n",
    "\n",
    "for title in titles:\n",
    "    if title.lower().find(query.lower()) > -1:\n",
    "        print(title, end=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5\n",
    "\n",
    "\n",
    "palindromes = []\n",
    "\n",
    "for ln in stdin:\n",
    "    words = ln.split()\n",
    "    for word in words:\n",
    "        cleaned_word = word.strip().lower()\n",
    "        if cleaned_word == cleaned_word[::-1]:\n",
    "            palindromes.append(word.strip())\n",
    "\n",
    "for word in sorted(set(palindromes)):\n",
    "    print(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6\n",
    "\n",
    "\n",
    "translit_map = {\n",
    "    \"А\": \"A\",\n",
    "    \"Б\": \"B\",\n",
    "    \"В\": \"V\",\n",
    "    \"Г\": \"G\",\n",
    "    \"Д\": \"D\",\n",
    "    \"Е\": \"E\",\n",
    "    \"Ё\": \"E\",\n",
    "    \"Ж\": \"Zh\",\n",
    "    \"З\": \"Z\",\n",
    "    \"И\": \"I\",\n",
    "    \"Й\": \"I\",\n",
    "    \"К\": \"K\",\n",
    "    \"Л\": \"L\",\n",
    "    \"М\": \"M\",\n",
    "    \"Н\": \"N\",\n",
    "    \"О\": \"O\",\n",
    "    \"П\": \"P\",\n",
    "    \"Р\": \"R\",\n",
    "    \"С\": \"S\",\n",
    "    \"Т\": \"T\",\n",
    "    \"У\": \"U\",\n",
    "    \"Ф\": \"F\",\n",
    "    \"Х\": \"Kh\",\n",
    "    \"Ц\": \"Tc\",\n",
    "    \"Ч\": \"Ch\",\n",
    "    \"Ш\": \"Sh\",\n",
    "    \"Щ\": \"Shch\",\n",
    "    \"Ы\": \"Y\",\n",
    "    \"Э\": \"E\",\n",
    "    \"Ю\": \"Iu\",\n",
    "    \"Я\": \"Ia\",\n",
    "    \"а\": \"a\",\n",
    "    \"б\": \"b\",\n",
    "    \"в\": \"v\",\n",
    "    \"г\": \"g\",\n",
    "    \"д\": \"d\",\n",
    "    \"е\": \"e\",\n",
    "    \"ё\": \"e\",\n",
    "    \"ж\": \"zh\",\n",
    "    \"з\": \"z\",\n",
    "    \"и\": \"i\",\n",
    "    \"й\": \"i\",\n",
    "    \"к\": \"k\",\n",
    "    \"л\": \"l\",\n",
    "    \"м\": \"m\",\n",
    "    \"н\": \"n\",\n",
    "    \"о\": \"o\",\n",
    "    \"п\": \"p\",\n",
    "    \"р\": \"r\",\n",
    "    \"с\": \"s\",\n",
    "    \"т\": \"t\",\n",
    "    \"у\": \"u\",\n",
    "    \"ф\": \"f\",\n",
    "    \"х\": \"kh\",\n",
    "    \"ц\": \"tc\",\n",
    "    \"ч\": \"ch\",\n",
    "    \"ш\": \"sh\",\n",
    "    \"щ\": \"shch\",\n",
    "    \"ы\": \"y\",\n",
    "    \"э\": \"e\",\n",
    "    \"ю\": \"iu\",\n",
    "    \"я\": \"ia\",\n",
    "    \"ъ\": \"\",\n",
    "    \"ь\": \"\",\n",
    "    \"Ъ\": \"\",\n",
    "    \"Ь\": \"\",\n",
    "}\n",
    "\n",
    "input_file = \"cyrillic.txt\"\n",
    "output_file = \"transliteration.txt\"\n",
    "\n",
    "\n",
    "with open(input_file, encoding=\"utf-8\") as infile:\n",
    "    text = infile.read()\n",
    "\n",
    "transliterated_text = \"\".join(translit_map.get(char, char) for char in text)\n",
    "\n",
    "with open(output_file, \"w\", encoding=\"utf-8\") as outfile:\n",
    "    outfile.write(transliterated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7\n",
    "\n",
    "\n",
    "file_name = stdin.read().strip()\n",
    "\n",
    "stats_numbers: list[int] = []\n",
    "\n",
    "with open(file_name, encoding=\"UTF-8\") as file_with_numbers:\n",
    "    for number_line in file_with_numbers:\n",
    "        stats_numbers.extend(int(nmb) for nmb in number_line.split())\n",
    "\n",
    "print(len(stats_numbers))\n",
    "print(len([pos_nmb for pos_nmb in stats_numbers if pos_nmb > 0]))\n",
    "print(min(stats_numbers))\n",
    "print(max(stats_numbers))\n",
    "print(sum(stats_numbers))\n",
    "print(f\"{sum(stats_numbers) / len(stats_numbers):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sdsce']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 8\n",
    "\n",
    "\n",
    "unique_words: set[str] = set()\n",
    "file_names = stdin.read().splitlines()\n",
    "file_names_in = file_names[:-1]\n",
    "file_name_out = file_names[-1]\n",
    "\n",
    "\n",
    "for file_name in file_names_in:\n",
    "    with open(file_name, encoding=\"UTF-8\") as file_in:\n",
    "        file_words = []\n",
    "        for words_line in file_in:\n",
    "            file_words.extend(words_line.split())\n",
    "        unique_words ^= set(file_words)\n",
    "\n",
    "with open(file_name_out, \"w\", encoding=\"UTF-8\") as file_out:\n",
    "    for word in sorted(unique_words):\n",
    "        print(word, file=file_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9\n",
    "\n",
    "\n",
    "\n",
    "util_file_names = stdin.read().splitlines()\n",
    "util_file_name_in = util_file_names[0]\n",
    "util_file_name_out = util_file_names[1]\n",
    "\n",
    "cleaned_lines: list[list[str]] = []\n",
    "\n",
    "with open(util_file_name_in, encoding=\"UTF-8\") as file_in:\n",
    "    for text_line in file_in:\n",
    "        words = text_line.strip().replace(\"\\t\", \"\").split()\n",
    "        if words:\n",
    "            cleaned_lines.append(words)\n",
    "\n",
    "with open(util_file_name_out, \"w\", encoding=\"UTF-8\") as file_out:\n",
    "    for words_list in cleaned_lines:\n",
    "        file_out.write(\" \".join(words_list) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10\n",
    "\n",
    "\n",
    "tail_file_input = stdin.read().splitlines()\n",
    "tail_file_name = tail_file_input[0]\n",
    "tail_file_lines = tail_file_input[1]\n",
    "\n",
    "tail_data = []\n",
    "\n",
    "with open(tail_file_name, encoding=\"UTF-8\") as file_in:\n",
    "    for ln in file_in:\n",
    "        tail_data.append(ln)\n",
    "for tail_line in tail_data[-int(tail_file_lines) :]:\n",
    "    print(tail_line, end=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 11\n",
    "\n",
    "\n",
    "user_input_files = stdin.read().splitlines()\n",
    "user_input_number_file = user_input_files[0]\n",
    "user_input_statistics_file = user_input_files[1]\n",
    "\n",
    "nmb_ls_full: list[int] = []\n",
    "\n",
    "with open(user_input_number_file, encoding=\"UTF-8\") as file_in:\n",
    "    for ln in file_in:\n",
    "        nmb_ls_full.extend(int(nmb_inp) for nmb_inp in ln.split())\n",
    "\n",
    "with open(user_input_statistics_file, \"w\", encoding=\"UTF-8\") as file_out:\n",
    "    positive_count = len(list(filter(lambda vl: vl > 0, nmb_ls_full)))\n",
    "    json.dump(\n",
    "        {\n",
    "            \"count\": len(nmb_ls_full),\n",
    "            \"positive_count\": positive_count,\n",
    "            \"min\": min(nmb_ls_full),\n",
    "            \"max\": max(nmb_ls_full),\n",
    "            \"sum\": sum(nmb_ls_full),\n",
    "            \"average\": f\"{sum(nmb_ls_full) / len(nmb_ls_full):.2f}\",\n",
    "        },\n",
    "        file_out,\n",
    "        ensure_ascii=False,\n",
    "        indent=4,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 12\n",
    "\n",
    "\n",
    "input_files = stdin.read().splitlines()\n",
    "input_file = input_files[0]\n",
    "even_file = input_files[1]\n",
    "odd_file = input_files[2]\n",
    "eq_file = input_files[3]\n",
    "\n",
    "with open(input_file, encoding=\"utf-8\") as f_in, open(\n",
    "    even_file, \"w\", encoding=\"utf-8\"\n",
    ") as f_even, open(odd_file, \"w\", encoding=\"utf-8\") as f_odd, open(\n",
    "    eq_file, \"w\", encoding=\"utf-8\"\n",
    ") as f_eq:\n",
    "\n",
    "    for line in f_in:\n",
    "        numbers = line.strip().split()\n",
    "        even_numbers = []\n",
    "        odd_numbers = []\n",
    "        eq_numbers = []\n",
    "\n",
    "        for num in numbers:\n",
    "            evens = sum(1 for digit in num if int(digit) % 2 == 0)\n",
    "            odds = len(num) - evens\n",
    "\n",
    "            if evens > odds:\n",
    "                even_numbers.append(num)\n",
    "            elif odds > evens:\n",
    "                odd_numbers.append(num)\n",
    "            else:\n",
    "                eq_numbers.append(num)\n",
    "\n",
    "        f_even.write(\" \".join(even_numbers) + \"\\n\")\n",
    "        f_odd.write(\" \".join(odd_numbers) + \"\\n\")\n",
    "        f_eq.write(\" \".join(eq_numbers) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 13\n",
    "\n",
    "\n",
    "user_inout_json_changes = stdin.read().splitlines()\n",
    "user_json_file_name = user_inout_json_changes[0]\n",
    "user_json_file_changes = user_inout_json_changes[1:]\n",
    "\n",
    "with open(user_json_file_name, encoding=\"UTF-8\") as file_in:\n",
    "    json_records = json.load(file_in)\n",
    "\n",
    "    for change in user_json_file_changes:\n",
    "        [key, val] = change.split(\" == \")\n",
    "        json_records[key] = val\n",
    "\n",
    "    with open(user_json_file_name, \"w\", encoding=\"UTF-8\") as file_out:\n",
    "        json.dump(json_records, file_out, ensure_ascii=False, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 14\n",
    "\n",
    "\n",
    "users_file, users_updates_file = stdin.read().splitlines()\n",
    "\n",
    "with open(users_file, encoding=\"UTF-8\") as file:\n",
    "    users_data = json.load(file)\n",
    "\n",
    "with open(users_updates_file, encoding=\"UTF-8\") as file:\n",
    "    users_updates_data = json.load(file)\n",
    "\n",
    "result: dict[str, dict[str, str]] = {}\n",
    "for user in users_data + users_updates_data:\n",
    "    name = user[\"name\"]\n",
    "    if name not in result:\n",
    "        result[name] = {}\n",
    "\n",
    "    for key, value in user.items():\n",
    "        if key == \"name\":\n",
    "            continue\n",
    "\n",
    "        result[name][key] = max(value, result[name].get(key, value))\n",
    "\n",
    "with open(users_file, \"w\", encoding=\"UTF-8\") as file:\n",
    "    json.dump(result, file, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 15\n",
    "\n",
    "\n",
    "usr_answr = [line.strip() for line in stdin.read().splitlines()]\n",
    "\n",
    "with open(\"scoring.json\", encoding=\"UTF-8\") as file:\n",
    "    test_groups = json.load(file)\n",
    "\n",
    "total_score = 0\n",
    "index = 0\n",
    "\n",
    "for group in test_groups:\n",
    "    group_points = group[\"points\"]\n",
    "    tests = group[\"tests\"]\n",
    "    test_count = len(tests)\n",
    "    points_per_test = group_points / test_count\n",
    "    passed_tests = 0\n",
    "\n",
    "    for test in tests:\n",
    "        if index < len(usr_answr) and usr_answr[index] == test[\"pattern\"]:\n",
    "            passed_tests += 1\n",
    "        index += 1\n",
    "\n",
    "    total_score += int(passed_tests * points_per_test)\n",
    "\n",
    "print(total_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 16\n",
    "\n",
    "\n",
    "search_input_params = sys.stdin.read().splitlines()\n",
    "search_query = \" \".join(search_input_params[0].split()).lower()\n",
    "search_files = search_input_params[1:]\n",
    "\n",
    "found_files = []\n",
    "\n",
    "for srch_fl in search_files:\n",
    "    with open(srch_fl, encoding=\"UTF-8\") as srch_file_in:\n",
    "        file_content = \" \".join(srch_file_in.read().split()).lower()\n",
    "        if search_query in file_content:\n",
    "            found_files.append(srch_fl)\n",
    "\n",
    "if found_files:\n",
    "    print(\"\\n\".join(found_files))\n",
    "else:\n",
    "    print(\"404. Not Found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 17\n",
    "\n",
    "with open(\"secret.txt\", encoding=\"UTF-8\") as f:\n",
    "    print(\"\".join([chr(ord(i) % 128) for i in f.read()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 18\n",
    "\n",
    "\n",
    "size = os.path.getsize(input())\n",
    "if size > 1024**3 - 1:\n",
    "    size = int(size / 1024**3) + 1\n",
    "    postfix = \"ГБ\"\n",
    "elif size > 1024**2 - 1:\n",
    "    size = int(size / 1024**2) + 1\n",
    "    postfix = \"МБ\"\n",
    "elif size > 1023:\n",
    "    size = int(size / 1024) + 1\n",
    "    postfix = \"КБ\"\n",
    "else:\n",
    "    postfix = \"Б\"\n",
    "print(str(size) + postfix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 19\n",
    "\n",
    "\n",
    "shift = int(sys.stdin.read().strip())\n",
    "\n",
    "with open(\"public.txt\", encoding=\"UTF-8\") as file:\n",
    "    text = file.read()\n",
    "\n",
    "encrypted_text = \"\"\n",
    "for char in text:\n",
    "    if \"a\" <= char <= \"z\":\n",
    "        encrypted_text += chr((ord(char) - ord(\"a\") + shift) % 26 + ord(\"a\"))\n",
    "    elif \"A\" <= char <= \"Z\":\n",
    "        encrypted_text += chr((ord(char) - ord(\"A\") + shift) % 26 + ord(\"A\"))\n",
    "    else:\n",
    "        encrypted_text += char\n",
    "\n",
    "with open(\"private.txt\", \"w\", encoding=\"UTF-8\") as file:\n",
    "    file.write(encrypted_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 20\n",
    "\n",
    "with open(\"numbers.num\", \"rb\") as file:\n",
    "    total_sum = 0\n",
    "    while chunk := file.read(2):\n",
    "        if len(chunk) < 2:\n",
    "            continue\n",
    "        total_sum += int.from_bytes(chunk, byteorder=\"big\")\n",
    "\n",
    "print(total_sum % 2**16)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SENATOROV",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
