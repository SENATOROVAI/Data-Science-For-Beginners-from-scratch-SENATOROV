"""Файл лога, в котором фиксируются пройденный материал."""

# 27/01/25
#
# 1. Создала аккаунт на GitHub и оформила его, использовав примеры из шаблонов.
# 2. Создала аккаунт на Kaggle и получила статус контрибьютора.
# 3. Создала аккаунт на ODS.AI.
# 4. Скачала и установила GitHub Desktop и Cursor, проверила настройки ранее установленного VS Code.
# 5. Установила плагины, настроила Cursor и VS Code к работе.
# 6. Установила CPython, Git и Conda.
# 7. Создала джамборд для учебы в canva.
# 8. Склонировала репозиторий, присоединилась к команде и создала свою ветку.
# 9. Запустила проверку файлов в репозитории командой pre-commit run --all-files.
# 10. Ознакомилась с процессом принятия и отправки коммитов.

# 27/01/25
#
# 1. Введение в линейную регрессию.
# - 1.1 Метод наименьших квадратов применяется для подбора коэфициентов в линейной регрессии (он оценивает параметры регрессии).
# - 1.2 если данные поддаются линейным взаимосвязям, то мы можем применять линейную модель.
# 2. Машинное обучение. 2 большие группы - с учителем и без учителя.
# - 2.1 Обучение с учителем: а) регрессионные модели и б) классификационные.
# - 2.2 Без учителя: кластеризация.
# 3. Рассмотрели порядок обучения модели.
# 4. Закон нормального распределения.
# - 4.1 Описывает, как часто различные значения случайной величины встречаются в наборе данных.
# - 4.2 Математическое ожидание — это среднее значение случайной величины.
# - 4.3 PDF - график плотности случайной величины.
# 5. Метод наименьших квадратов (для подбора весов).
# - 5.1 Его задача - минимизировать сумму квадратов регрессионных остатков.

# 02/02/25
#
# 1. Теорема Гаусса Маркова: МНК является лучшей линейной несмещенной оценкой.
# - 1.1 Несмещенная модель. Суть: когда мы можем взять какое-то подмножество точек из целого множества, и математическое ожидание этого подмножества будет совпадать с таковым у самого множества.
# - 1.2 Гомоскедастичность - свойство, означающее постоянство условной дисперсии вектора или последовательности случайных величин. Означает одинаковый разброс величин относительно нашей линии фита.
#
# - Как наглядно выглядят гомоскедастичность и гетероскедастичность:
# ![Гетероскедастичность](https://myslide.ru/documents_3/2b677335f0177d29121e558fe4d3215c/img3.jpg)
#
# 2. Математическое ожидание.
# 3. Понятие дисперсии и стандартного отклонения. Если дисперсия фиксирована и не зависит от входных данных, такая модель называется гомоскедастической регрессией, а если зависит - гетероскедастической.
# 4. Понятия средняя, медиана и мода.
# - 4.1 Робастная оценка - это и есть медиана, устойчива к выбросам.
# - 4.2 Среднее - сумма всех значений деленная на количество этих значений.
# - 4.2 Медиана - значение, которое делит отсортированный набор на две равные части.
# - 4.3 Мода - значение, которое встречается в выборке чаще всего.

# 03/02/25
#
# 1. Задача обучения модели - найти такой алгоритм А (решающую функцию), приближающую у на всем множестве Х. То есть мы хотим найти функцию, которая сможет апроксимировать - даст максимальное приближение к истинному алгоритму.
# 2. Признаки объекта. Типы признаков.
# 3. Функция потерь. Эмпирический риск. Минимизация эмпирического риска.
# 4. Функция потерь.
# 5. Градиент - это вектор частных производных, который показывает направление наискорейшего роста. Антиградиент.
# 6. Learning rate - шаг, с какой скоростью мы хотим обучать модель. Подбирается до обучения модели.
# 7. Геометрический смысл частных производных функции двух переменных.

# 07/02/25
#
# 1. Функция потерь. MSE.
# 2. Взятие производной по каждой переменной в функции потерь путем блокировки (заморозки) других переменных в этой функции.
# 3. Градиент - производная по нескольким переменным.
# 4. Градиент по сути это направление наискорейшего роста функции, поэтому мы берем антиградиент, так как нам нужно добраться до глобального минимума.
# 5. Задача оптимизации - найти глобальный минимум функции потерь.
#

# 10/02/25
#
# 1. Градиент - это вектор частных производных. Векторная форма записи градиента.
# 2. Понятие одномерной и многомерной линейно регрессии.
# 3. Средняя абсолютная ошибка (MAE). Отличие МАЕ от MSE.
# 4. Learning rate. Градиентный спуск. Learning rate отвечает за шаг градиентного спуска вниз. Learning rate подбирается до обучения.
# 5. Взятие частной производной от функции MAE.
# 6. Субградиент - это вектор. Множество субградиентов называется субдифференциал.
# 7. Проблема производной MAE - неопределенность в нуле.
# 8. Функция знака - альтернативная функция, которая похожа на производную MAE и определена в нуле. Ее мы будем использовать в python.
# 9. Вместо использование функции знака, в качестве второго подхода можно использовать доопределение функции.
# 10. Способы поиска коэфициентов регрессии: итерационный (с помощью градиентного способа) и аналитический.
# 11. Аналитический способ - самый точный способ для поиска коэфициентов.

# 14/02/25
#
# 1. Экзамен по функции потерь и производным.
# 2. Аналитический способ решения МНК.
#  - RSS - Residual Sum of Squares - сумма квадратов остатков.
#  - Взятие частных производных.
#  - Решение системы уравнений.
# 3. Аналитическое решение является самым точным из всех. Но если будет очень много переменных х (фич), то процесс нахождения весов будет достаточно долгим.
# 4. Вычисление аналитическим методом на примере задачи размерах и продажах торговой точки с 5 магазинами.

# 17/02/25
#
# ## Реализация линейной регрессии и функции потерь на python.
# 1. Библиотеки, которые нам понадобятся для вычислений:
#  - numpy
#  - pandas
#  - matplotlib
#  - math
#  - sympy (для работы с символьными вычислениями)
# 2. Понятие критерия остановы.
# 3. Для того, чтобы осуществить итеративный поиск весов, необходимо задать learning rate и количество итераций. Как только разница между двумя значениями весов будет меньше epsilon (который мы тоже задаем сами), нам следует остановиться в поиске минимума.
# 4. Epsilon подбирается в зависимости от задачи.
# 5. Моделирование на python. Создание датафрейма и визуализация точек с на графике. Подключение библиотек:
#  - import numpy as np
#  - import matplotlib.pyplot as plt
#  - import pandas as pd
